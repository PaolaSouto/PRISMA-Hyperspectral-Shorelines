{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed84f1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34666564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from osgeo import osr, ogr, gdal\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "import json\n",
    "from matplotlib import colors as mcolors\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "from shapely import geometry\n",
    "import time \n",
    "import pyproj\n",
    "from shapely.affinity import rotate\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "plt.ion()\n",
    "%matplotlib qt\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "\n",
    "sys.path.append('/media/sf_VBox_Shared/PAOLA/PRISMA3/')\n",
    "\n",
    "from PRISMA_SDS import PRIS_tools_v2, PRIS_img_v2, PRIS_profiles_v2, PRIS_Shoreline_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f5839",
   "metadata": {},
   "source": [
    "**DEFINE THE FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8168d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridRaster(dir_img, crs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Stores the image cells into a pandas geodatabase (cells as polygon features)\n",
    "    \"\"\"\n",
    "    \n",
    "    raster = gdal.Open(dir_img)\n",
    "    geoT = raster.GetGeoTransform()\n",
    "    pixWidth = geoT[1]\n",
    "    n_cols = raster.RasterXSize\n",
    "    n_rows = raster.RasterYSize\n",
    "    \n",
    "    row = []\n",
    "    col = []\n",
    "    pol = []\n",
    "    \n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            \n",
    "            Xcoord, Ycoord = PRIS_tools_v2.pixel_to_world(raster, c, r)\n",
    "            upper_left = [Xcoord, Ycoord]\n",
    "            bottom_left = [Xcoord, Ycoord - pixWidth]\n",
    "            upper_right = [Xcoord + pixWidth, Ycoord]\n",
    "            bottom_right = [Xcoord + pixWidth, Ycoord - pixWidth]\n",
    "            \n",
    "            poly = geometry.Polygon([bottom_left, upper_left, upper_right, bottom_right, bottom_left])\n",
    "            \n",
    "            pol.append(poly)\n",
    "            row.append(r)\n",
    "            col.append(c)\n",
    "            \n",
    "    dataframe = pd.DataFrame({'row':row, 'col':col, 'geometry':pol})\n",
    "    grid = gpd.GeoDataFrame(dataframe, crs = crs)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d9af4",
   "metadata": {},
   "source": [
    "**ITERATE THROUGH THE PROFILES SEARCHING THE INTERFACE PIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980295f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProfileBounds(pr):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the profile BB\n",
    "    \"\"\"\n",
    "    \n",
    "    xmin = pr.bounds['minx'].values[0]\n",
    "    xmax = pr.bounds['maxx'].values[0]\n",
    "    ymin = pr.bounds['miny'].values[0]\n",
    "    ymax = pr.bounds['maxy'].values[0]\n",
    "    \n",
    "    return xmin, xmax, ymin, ymax\n",
    "\n",
    "def ProfileBeginning(pr):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gives the profile starting coordinate\n",
    "    \"\"\"\n",
    "    \n",
    "    pr.reset_index(inplace = True)\n",
    "    coords = [(coords) for coords in list(pr.geometry[0].coords)]\n",
    "    x1 = coords[0][0]\n",
    "    y1 = coords[0][1]\n",
    "    \n",
    "    return x1, y1\n",
    "\n",
    "def EuclideanDistance(x1, y1, x2, y2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the euclidean distance between 2 points\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    dis_X = (x1 - x2)**2\n",
    "    dis_Y = (y1 - y2)**2\n",
    "    dist = np.sqrt(dis_X + dis_Y)\n",
    "\n",
    "    return dist\n",
    "\n",
    "def MidPointDistances(overlayed, x_prx, y_prx):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain the midpoint of a segment\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    distances = []\n",
    "\n",
    "    for point in overlayed['midpoint']:\n",
    "\n",
    "        mid_point = list(point.coords)\n",
    "        x2, y2 = mid_point[0][0], mid_point[0][1]\n",
    "\n",
    "        distances.append(EuclideanDistance(x_prx, y_prx, x2 ,y2))\n",
    "        \n",
    "    overlayed['dist_midpoint'] = distances\n",
    "    overlayed.sort_values(by = 'dist_midpoint', ascending = True, inplace = True)\n",
    "    \n",
    "    return overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82aa8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanReflectances(overlayed, arr):\n",
    "    \n",
    "    \"\"\"\n",
    "    Add to the overlated geodatabase the mean reflectance value of the particular pixel\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_reflectance = []\n",
    "\n",
    "    for r, c in zip(overlayed['row'], overlayed['col']):\n",
    "        ss = arr[r,c,:]\n",
    "        mean_reflectance.append(np.mean(ss))\n",
    "\n",
    "    overlayed['mean_R'] = mean_reflectance\n",
    "    \n",
    "    return overlayed\n",
    "\n",
    "def Interpolate_R_PR(overlayed, interval):\n",
    "    \n",
    "    x_old = np.array(overlayed['dist_midpoint'])\n",
    "    y_old = np.array(overlayed['mean_R'])\n",
    "    \n",
    "    x_new = np.arange(x_old[0], x_old[-1], interval)\n",
    "    f = interpolate.interp1d(x_old, y_old, kind = 'cubic')\n",
    "    y_new =  f(x_new)\n",
    "    \n",
    "    deriv_new = y_new[1:] - y_new[:-1]\n",
    "    idd_inter_new = np.argmin(deriv_new)\n",
    "    inter = y_new[idd_inter_new]\n",
    "    \n",
    "    return idd_inter_new, inter, x_new, y_new, deriv_new\n",
    "\n",
    "def SSInterfacePixe(GeoT, arr, lon, lat):\n",
    "\n",
    "    # Pixel containing the transition coordinate\n",
    "    \n",
    "    col, row = PRIS_tools_v2.world_to_pixel(GeoT, lon, lat)\n",
    "    \n",
    "    # Get the spectral signature\n",
    "    \n",
    "    ss = arr[row, col, :]\n",
    "    \n",
    "    return col, row, ss\n",
    "    \n",
    "    \n",
    "\n",
    "def PlotProfileValues(paths, date, idd_inter_new, inter, x_new, y_new, deriv_new, pr):\n",
    "\n",
    "        \n",
    "    pathS0 = os.path.join(paths['Interface_pix_plot'], 'MeanSS_pr')\n",
    "    \n",
    "    if not os.path.exists(pathS0):\n",
    "        os.mkdir(pathS0)\n",
    "    \n",
    "    \n",
    "    name = 'MeanSS_'+ pr + '_' + date + '.png'\n",
    "\n",
    "    pathS = os.path.join(pathS0, date)\n",
    "\n",
    "    if not os.path.exists(pathS):\n",
    "        os.mkdir(pathS)\n",
    "\n",
    "\n",
    "        \n",
    "    plt.scatter(idd_inter_new, inter, s=150, c='firebrick', alpha = 0.5, label = 'interface')\n",
    "    plt.plot(y_new, marker = 'o', color='royalblue', label = 'mean reflectance') # royalblue\n",
    "    plt.plot(deriv_new, marker = 'o', color = 'slategray', label = 'derived') # #  skyblue\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_color('grey')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('grey')\n",
    "    ax.grid(color='gainsboro', linestyle = '--', axis = 'y')\n",
    "\n",
    "    plt.title('Profile '+ pr, fontsize = 15)\n",
    "    plt.xlabel(\"d (m)\", fontsize = 15)\n",
    "    plt.ylabel(\"Mean Reflectance\", fontsize = 15)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(pathS, name))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dace76",
   "metadata": {},
   "source": [
    "**FUNCTIONS RELATED TO THE PROFILE DIRECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f7da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AzimuthAngle(coor_pr_i, coor_pr_f):\n",
    "    angle = (180/np.pi) * math.atan2(coor_pr_f[0] - coor_pr_i[0], coor_pr_f[1] -coor_pr_i[1])\n",
    "    \n",
    "    if angle < 0:\n",
    "        angle = (angle + 360)%360\n",
    "    return(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c49bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(vA, vB):\n",
    "    return vA[0]*vB[0] + vA[1] * vB[1]\n",
    "\n",
    "def Cal_ang(lineA, lineB):\n",
    "    vA = [(lineA[0][0] - lineA[1][0]), (lineA[0][1] - lineA[1][1])]\n",
    "    vB = [(lineB[0][0] - lineB[1][0]), (lineB[0][1] - lineB[1][1])]\n",
    "\n",
    "    # Get dot profuct\n",
    "    dot_pro = dot(vA, vB)\n",
    "    # Get magnitudes\n",
    "    magA = dot(vA, vA)**0.5\n",
    "    magB = dot(vB, vB)**0.5\n",
    "    # Get cosine value\n",
    "    cos_ = dot_pro/magA/magB\n",
    "    \n",
    "    # Get angle in radians and then convert to degrees\n",
    "    if dot_pro == 0:\n",
    "\n",
    "        ang_deg = np.degrees(np.arccos(0)) \n",
    "    else:\n",
    "        angle = math.acos(dot_pro/magB/magA)\n",
    "        # Doing angle <- angle mod 360\n",
    "        ang_deg = math.degrees(angle)%360\n",
    "\n",
    "    if ang_deg - 180 >= 0:\n",
    "        return 360 - ang_deg\n",
    "    else:\n",
    "        return ang_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42fc77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used only to check if a profiles is fully contained on the image BB\n",
    "\n",
    "def ImageBB(paths, date):\n",
    "    \n",
    "    imgName = [f for f in os.listdir(paths['PanSharp_RGB']) if f.endswith('.tiff') and date in f][0]\n",
    "    img = gdal.Open(os.path.join(paths['PanSharp_RGB'], imgName))\n",
    "\n",
    "    nC = img.RasterXSize\n",
    "    nR = img.RasterYSize\n",
    "\n",
    "    geoT = img.GetGeoTransform()\n",
    "    res = geoT[1]\n",
    "    xmin = min(geoT[0], geoT[0] + nC * geoT[1])\n",
    "    xmax = max(geoT[0], geoT[0] + nC * geoT[1])\n",
    "    ymin = min(geoT[3], geoT[3] + nR * geoT[5])\n",
    "    ymax = max(geoT[3], geoT[3] + nR * geoT[5])\n",
    "    north = [(xmin, ymin), (xmin, ymax)]\n",
    "    \n",
    "    return xmin, xmax, ymin, ymax, north"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ea4f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_plotInfo(paths, date, pr, idd_inter_new, inter, x_new, y_new, deriv_new ):\n",
    "    \n",
    "    filename = '{:s}_MeanR_{:d}_{:.20f}.txt'.format(pr,idd_inter_new, inter)\n",
    "    pathS0 = paths['Interface_pix_txtPlot']\n",
    "    \n",
    "    pathS = os.path.join(pathS0, date)\n",
    "\n",
    "    if not os.path.exists(pathS):\n",
    "        os.mkdir(pathS)\n",
    "    \n",
    "    dir_fileout = os.path.join(pathS, filename)\n",
    "    \n",
    "    #fileout = open(dir_fileout, \"w\")\n",
    "    \n",
    "    b = deriv_new[-1]\n",
    "    \n",
    "    deriv_new2 = np.append(deriv_new,b)\n",
    "    \n",
    "    info = pd.DataFrame({'x':x_new, 'y':y_new, 'deriv':deriv_new2})\n",
    "    info.to_csv(dir_fileout, index = False)\n",
    "    \n",
    "    #for i in range(len(x_new)):\n",
    "\n",
    "        #fileout.write('{:9.3f} {:9.3f} {:9.3f}\\n'.format(x_new[i], y_new[i], deriv_new2[i]))\n",
    "                         \n",
    "    #fileout.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ed95780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def AnaliziyngProfiles(profiles, date, grid, arr, img_BB, GeoT, plot):\n",
    "    \n",
    "    # Generate the DataFrame\n",
    "\n",
    "    lon = []\n",
    "    lat = []\n",
    "    \n",
    "    cols = []\n",
    "    rows = []\n",
    "    SS = []\n",
    "    PRS = []\n",
    "\n",
    "    for pr in profiles['PR']:\n",
    "        \n",
    "\n",
    "        print(\"\", end=f\"\\r Analyzing {pr}\")\n",
    "        \n",
    "        # Search the profile\n",
    "\n",
    "        prx = profiles[profiles['PR'] == pr]\n",
    "        prx.reset_index(inplace = True, drop = True)\n",
    "        \n",
    "        if not img_BB.contains(prx['geometry'][0]):\n",
    "            continue\n",
    "\n",
    "        # Get pixel initial coordinate\n",
    "\n",
    "        x_prx, y_prx = ProfileBeginning(prx)\n",
    "        \n",
    "        x1, y1 = prx.boundary[0][0].xy[0][0], prx.boundary[0][0].xy[1][0]\n",
    "        x2, y2 = prx.boundary[0][1].xy[0][0], prx.boundary[0][1].xy[1][0]\n",
    "        col1, row1 = PRIS_tools_v2.world_to_pixel(GeoT, x1, y1)\n",
    "        col2, row2 = PRIS_tools_v2.world_to_pixel(GeoT, x2, y2)\n",
    "\n",
    "        rowmin = min(row1, row2)\n",
    "        rowmax = max(row1, row2)\n",
    "        colmin = min(col1, col2)\n",
    "        colmax = max(col1, col2)\n",
    "\n",
    "        new_grid = grid[(grid['row'] >= rowmin) & (grid['row']<=rowmax) & (grid['col'] <= colmax) & (grid['col'] >= colmin)]\n",
    "        new_grid.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "        # Overlay the grid and the profiles geometries\n",
    "\n",
    "        overlayed = gpd.overlay(prx, new_grid, how = 'intersection')\n",
    "        overlayed.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        ## Check that the length of the obtained pixels is the same of the entire profile\n",
    "        \n",
    "\n",
    "        assert [np.abs(overlayed['geometry'].length.sum() - prx['geometry'].length) < 1.e-6][0][0]\n",
    "\n",
    "        ## Check that all the distances are smaller than 5*sqrt(2)\n",
    "\n",
    "        overlayed['length'] =  [line.length for line in overlayed['geometry']]\n",
    "        overlayed['bool'] = overlayed['length'] < 5 * np.sqrt(2)\n",
    "        \n",
    "\n",
    "        assert overlayed['bool'].unique()[0]\n",
    "\n",
    "        ## Obtain the mid point of the segments\n",
    "\n",
    "        overlayed['midpoint'] = overlayed.apply(lambda row: row['geometry'].centroid, axis=1) #Find centroid\n",
    "\n",
    "        ## Calculate the distances of each midpoint to the beginning profile point\n",
    "\n",
    "        overlayed = MidPointDistances(overlayed, x_prx, y_prx)\n",
    "\n",
    "        ## Add the mean reflectances\n",
    "        \n",
    "\n",
    "        overlayed = MeanReflectances(overlayed, arr)\n",
    "        overlayed.to_csv(os.path.join(paths['Interface_pix_txtPlot'], pr + '_Overlayed.csv'))\n",
    "\n",
    "        ## Interpolate distances an reflectances\n",
    "\n",
    "        idd_inter_new, inter, x_new, y_new, deriv_new = Interpolate_R_PR(overlayed, 0.25)\n",
    "        \n",
    "        Save_plotInfo(paths, date, pr, idd_inter_new, inter, x_new, y_new, deriv_new )\n",
    "\n",
    "        ## Save and generate the plots\n",
    "        \n",
    "        if plot:\n",
    "\n",
    "            PlotProfileValues(paths, date, idd_inter_new, inter, x_new, y_new, deriv_new, pr) \n",
    "\n",
    "        # Now we know which is the point we can obtain the shoreline\n",
    "\n",
    "        new_length = x_new[idd_inter_new]\n",
    "\n",
    "        # We have to know which is the profile angle to be able to \n",
    "        \n",
    "        xmin_pr, xmax_pr, ymin_pr, ymax_pr = ProfileBounds(prx)\n",
    "        \n",
    "        north = [(xmin_pr, ymin_pr), (xmin_pr, ymax_pr)] # nortth direction\n",
    "        \n",
    "        coords = [(coords) for coords in list(prx.geometry[0].coords)]\n",
    "        coor_pr_i, coor_pr_f = [coords[i] for i in (0,-1)]\n",
    "        slp = (coor_pr_f[1] - coor_pr_i[1]) / (coor_pr_f[0] - coor_pr_i[0]) # slope profile\n",
    "        pr_line = [(coor_pr_i[0], coor_pr_i[1]), (coor_pr_f[0], coor_pr_f[1])]\n",
    "        \n",
    "        angle = AzimuthAngle(coor_pr_i, coor_pr_f)\n",
    "        Deg_rot = Cal_ang(north, pr_line)\n",
    "        \n",
    "        start = Point(coor_pr_i[0], coor_pr_i[1])\n",
    "        end = Point(start.x  , start.y + new_length)\n",
    "        Line = LineString([start, end])\n",
    "        \n",
    "\n",
    "        if (90 < angle <270) and (slp < 0):\n",
    "\n",
    "            pr_new = rotate(Line , -Deg_rot , origin = [coor_pr_i[0], coor_pr_i[1]], use_radians = False)\n",
    "\n",
    "        if (180 < angle <270) and (slp > 0):\n",
    "\n",
    "            pr_new = rotate(Line , Deg_rot , origin = [coor_pr_i[0], coor_pr_i[1]], use_radians = False)\n",
    "\n",
    "        if (0 < angle <90) and (slp > 0):\n",
    "\n",
    "            pr_new = rotate(Line , -Deg_rot , origin = [coor_pr_i[0], coor_pr_i[1]], use_radians = False)\n",
    "            \n",
    "        if (270< angle < 360) and (slp < 0):\n",
    "            \n",
    "            pr_new = rotate(Line , Deg_rot , origin = [coor_pr_i[0], coor_pr_i[1]], use_radians = False)\n",
    "        \n",
    "        \n",
    "        coords_n = [(coords) for coords in list(pr_new.coords)]\n",
    "        coor_pr_iN, coor_pr_fN = [coords_n[i] for i in (0,-1)]\n",
    "        \n",
    "        col, row, ss = SSInterfacePixe(GeoT, arr, coor_pr_fN[0], coor_pr_fN[1])\n",
    "        \n",
    "        cols.append(col)\n",
    "        rows.append(row)\n",
    "        SS.append(list(ss))\n",
    "        PRS.append(pr)\n",
    "\n",
    "        lon.append(coor_pr_fN[0])\n",
    "        lat.append(coor_pr_fN[1])\n",
    "        \n",
    "    interface_pix = pd.DataFrame({'pr':PRS, 'row':rows, 'col':cols, 'signature':SS})\n",
    "\n",
    "    return lon, lat, interface_pix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c47dda",
   "metadata": {},
   "source": [
    "**STORE THE INFORMATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb5b4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_geojson(paths,shapefile, imagename, lon, lat):\n",
    "    \n",
    "    # Save into the geojson file\n",
    "    \n",
    "    geojson = PRIS_tools_v2.coor_to_geojson(lon, lat)\n",
    "    \n",
    "    filename = imagename.split('.')[0] + '_' + 'profiles_'+   '_'.join(shapefile.split('_')[2:4]) + '.geojon'\n",
    "    \n",
    "    dir_store = os.path.join(paths['SDS'], 'derivative')\n",
    "    \n",
    "    if not os.path.exists(dir_store):\n",
    "        os.mkdir(dir_store)\n",
    "    \n",
    "    PRIS_tools_v2.save_geojson(dir_store, filename, geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ea439f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveSubPixel_Txt(paths, shapefile ,imagename, lon, lat):\n",
    "    \n",
    "    dir_img =  os.path.join(paths['PanSharp_Square_Cropped'], imagename)\n",
    "    raster = gdal.Open(dir_img)\n",
    "    geoT = raster.GetGeoTransform()\n",
    "    minx = geoT[0]\n",
    "    maxy = geoT[3]\n",
    "    \n",
    "    upper_left = [minx, maxy]\n",
    "    \n",
    "    filename = imagename.split('.')[0] + '_' + 'profiles_'+   '_'.join(shapefile.split('_')[2:4]) + '.txt'\n",
    "    \n",
    "    dir_store = os.path.join(paths['SDS'], 'derivative')\n",
    "    \n",
    "    if not os.path.exists(dir_store):\n",
    "        os.mkdir(dir_store)\n",
    "        \n",
    "    dir_fileout = os.path.join(paths['SDS'], 'derivative', filename)\n",
    "    \n",
    "    fileout = open(dir_fileout, \"w\")\n",
    "\n",
    "    for lo, la in zip(lon, lat):\n",
    "            \n",
    "        sub_col = (lo - upper_left[0])/geoT[1]\n",
    "        sub_row = (upper_left[1] - la)/geoT[1]\n",
    "        fileout.write('{:9.3f} {:9.3f}\\n'.format(sub_row, sub_col))\n",
    "                         \n",
    "    fileout.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc99cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0994f4e5",
   "metadata": {},
   "source": [
    "**MAIN FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab58dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubPixProfiles(paths):\n",
    "    \n",
    "    # Load the images we have to analyze each one\n",
    "    \n",
    "    imgs = [f for f in os.listdir(paths['PanSharp_Square_Cropped']) if f.endswith('tiff')]\n",
    "    \n",
    "    \n",
    "    for imagename in imgs:\n",
    "        \n",
    "        date = imagename.split('_')[1]\n",
    "        \n",
    "        if date == '20201015':\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        print('Analyzing imgage: ', str(imagename), flush = True)\n",
    "      \n",
    "        \n",
    "        dir_img =  os.path.join(paths['PanSharp_Square_Cropped'], imagename)\n",
    "        print('leo imagen')\n",
    "        arr, arr_rgb = PRIS_img_v2.numpy_from_tiff(dir_img, True)\n",
    "        print('he leido imagen')\n",
    "        img = gdal.Open(dir_img)\n",
    "        GeoT = img.GetGeoTransform()\n",
    "        proj = osr.SpatialReference(wkt=img.GetProjection())\n",
    "        crs = pyproj.CRS(\"EPSG:\" + proj.GetAttrValue('AUTHORITY',1))\n",
    "\n",
    "        \n",
    "        # CREATE THE RASTER GRID GEODATAFRAME\n",
    "        \n",
    "        #grid = GridRaster(dir_img, crs)\n",
    "\n",
    "        dir_grids = os.path.join(paths['scene'] , beach, 'QGIS', 'Img_grid')\n",
    "        gridName = [f for f in os.listdir(dir_grids) if date in f and 'Upsampling' not in f][0]\n",
    "        grid = gpd.read_file(os.path.join(dir_grids, gridName))\n",
    "        \n",
    "        # Image Bounding Box\n",
    "        \n",
    "        xmin, xmax, ymin, ymax, north = ImageBB(paths, date)\n",
    "        img_BB = Polygon([[xmin,ymin], [xmin, ymax], [xmax, ymax], [xmax, ymin]])\n",
    "        \n",
    "        ## LOAD THE PROFILES\n",
    "        \n",
    "        shapefiles = [f for f in os.listdir(paths['Profiles']) if f.endswith('.shp') and date in f]\n",
    "        \n",
    "        # if there is more than one profile per date (inclination study) we must iterate throught\n",
    "        \n",
    "        for shapefile in shapefiles:\n",
    "            \n",
    "            print('SDS for profiles: ', shapefile)\n",
    "            \n",
    "            filename = imagename.split('.')[0] + '_' + 'profiles_'+   '_'.join(shapefile.split('_')[2:4]) + '.txt'\n",
    "\n",
    "            #if os.path.exists(os.path.join(paths['SDS'], 'derivative', filename)):\n",
    "                #print('Already calculated')\n",
    "                #continue\n",
    "        \n",
    "            profile_path = os.path.join(paths['Profiles'],shapefile) \n",
    "\n",
    "            if os.path.exists(profile_path):\n",
    "                print('Load the profiles')\n",
    "                profiles = gpd.read_file(profile_path, encoding=\"utf-8\")\n",
    "                crs_pr = profiles.crs\n",
    "            else:\n",
    "                print('No profiles')\n",
    "                \n",
    "            if '90_0' in shapefile:\n",
    "                plot = False\n",
    "            else:\n",
    "                plot = False\n",
    "\n",
    "            # ITERATE THROUGH THE PROFILES\n",
    "            if '90_0' in shapefile:\n",
    "                lon, lat, interface_pix = AnaliziyngProfiles(profiles,date, grid,arr, img_BB, GeoT, plot)\n",
    "            \n",
    "            # SAVE THE INTERFACE_PIX DATAFRAME\n",
    "            \n",
    "            # This information is saved only for the k-means shoreline (perp pr)\n",
    "            \n",
    "            if '90_0' in shapefile:\n",
    "                \n",
    "                name_csv = 'InterfacePix_' + date +'_'+('_').join(shapefile.split('.')[0].split('_')[-3:-1]) + '.csv'\n",
    "        \n",
    "                interface_pix.to_csv(os.path.join(paths['Interface_pix_csv'], name_csv), index = False)\n",
    "\n",
    "            # SAVE THE SHORELINE\n",
    "\n",
    "            Save_geojson(paths,shapefile, imagename, lon, lat)\n",
    "            SaveSubPixel_Txt(paths,shapefile, imagename, lon, lat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3000a",
   "metadata": {},
   "source": [
    "**TRY THE ALGORITHM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0725dcd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR03\n",
      "Analyzing imgage:  FR_20210312_0101_0101_01010_00101.tiff\n",
      "leo imagen\n",
      "he leido imagen\n",
      "SDS for profiles:  FR_20210312110747_90_0_pr.shp\n",
      "Load the profiles\n",
      " Analyzing PR366"
     ]
    }
   ],
   "source": [
    "path0 = '/media/sf_VBox_Shared/PAOLA/PRISMA_FOAM/'\n",
    "scene = 'FR'\n",
    "\n",
    "beaches = [f for f in os.listdir(os.path.join(path0, 'SCENES', scene)) if 'FR03' in f] #if '01' in f\n",
    "\n",
    "for beach in beaches:\n",
    "    \n",
    "    print(beach)\n",
    "    \n",
    "    paths = PRIS_tools_v2.generate_structure(path0, scene, beach)\n",
    "    \n",
    "    dir_inter_Rat_txtPlot = os.path.join(paths['scene'], beach, 'Results', 'Interface_pix', 'txtPlot')\n",
    "    \n",
    "    if not os.path.exists(dir_inter_Rat_txtPlot):\n",
    "        os.makedirs(dir_inter_Rat_txtPlot)\n",
    "        \n",
    "    \n",
    "    paths['Interface_pix_txtPlot'] = dir_inter_Rat_txtPlot\n",
    "    \n",
    "    SubPixProfiles(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9dcce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
